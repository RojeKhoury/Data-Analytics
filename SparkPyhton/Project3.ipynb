{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.0.14:4047\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.0-preview2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"PySparkShell\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as fn\n",
    "from pyspark.sql.types import *\n",
    "import string\n",
    "from pyspark.sql.functions import lit\n",
    "import pyspark.sql.column\n",
    "import string\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inputBooks = sc.wholeTextFiles(\"project3Data/*.txt\")\n",
    "inputBaseFillter=inputBooks.map(lambda (BookName,Text):\\\n",
    "(BookName.replace(\"file:/home/roje/Desktop/project3/project3Data/\",\"\").replace(\".txt\",\"\"),\\\n",
    " str(Text.encode(\"utf-8-sig\"))))\n",
    "NumberOfFiles=inputBooks.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "FirstJob = inputBaseFillter.map(lambda (N,T): (N, (','.join([''.join(e for e in y if e in string.printable).strip('\\\"') for y in T.split(',')]))\\\n",
    "                .replace(\"?\",\"\")\\\n",
    "                .replace(\"\\\"\",\" \")\\\n",
    "                .replace(\"*\",\" \")\\\n",
    "                .replace(\"-\",\" \")\\\n",
    "                .replace(\".\",\" \")\\\n",
    "                .replace(\"!\",\" \")\\\n",
    "                .replace(\",\",\" \")\\\n",
    "                .replace(\"'\",\" \")\\\n",
    "                .replace(\"/\",\" \")\\\n",
    "                .replace(\"=\",\" \")\\\n",
    "                .replace(\"(\",\" \")\\\n",
    "                .replace(\")\",\" \")\\\n",
    "                .replace(\";\",\" \")\\\n",
    "                .replace(\"[\",\" \")\\\n",
    "                .replace(\":\",\" \")\\\n",
    "                .replace(\"'\",\" \")\\\n",
    "                .replace(\"]\",\" \")\\\n",
    "                .replace(\"+\",\" \")\\\n",
    "                .replace(\"_\",\" \")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SecoundJob=FirstJob.map(lambda (N,T):(N,T.lower().replace(\" ourselves \",\" \").replace(\" hers \",\" \").replace(\" between \",\" \").replace(\" yourself \",\" \")\\\n",
    ".replace(\" but \",\" \").replace(\" again \",\" \").replace(\" there \",\" \").replace(\" about \",\" \")\\\n",
    ".replace(\" once \",\" \").replace(\" during \",\" \").replace(\" out \",\" \").replace(\" very \",\" \")\\\n",
    ".replace(\" having \",\" \").replace(\" with \",\" \").replace(\" they \",\" \").replace(\" own \",\" \")\\\n",
    ".replace(\" an \",\" \").replace(\" be \",\" \").replace(\" some \",\" \").replace(\" for \",\" \").replace(\" do \",\" \")\\\n",
    ".replace(\" its \",\" \").replace(\" yours \",\" \").replace(\" such \",\" \").replace(\" into \",\" \").replace(\" of \",\" \")\\\n",
    ".replace(\" most \",\" \").replace(\" itself \",\" \").replace(\" other \",\" \").replace(\" off \",\" \").replace(\" is \",\" \")\\\n",
    ".replace(\" s \",\" \").replace(\" am \",\" \").replace(\" or \",\" \").replace(\" who \",\" \").replace(\" as \",\" \")\\\n",
    ".replace(\" from \",\" \").replace(\" him \",\" \").replace(\" each \",\" \").replace(\" the \",\" \").replace(\" themselves \",\" \")\\\n",
    ".replace(\" until \",\" \").replace(\" below \",\" \").replace(\" are \",\" \").replace(\" we \",\" \").replace(\" these \",\" \")\\\n",
    ".replace(\" your \",\" \").replace(\" his \",\" \").replace(\" through \",\" \").replace(\" don \",\" \").replace(\" nor \",\" \").replace(\" me \",\" \").replace(\" were \",\" \").replace(\" her \",\" \").replace(\" more \",\" \").replace(\" himself \",\" \").replace(\" this \",\" \").replace(\" down \",\" \").replace(\" should \",\" \").replace(\" our \",\" \").replace(\" their \",\" \").replace(\" while \",\" \").replace(\" above \",\" \").replace(\" both \",\" \").replace(\" up \",\" \").replace(\" to \",\" \").replace(\" ours \",\" \").replace(\" had \",\" \").replace(\" she \",\" \").replace(\" all \",\" \").replace(\" no \",\" \").replace(\" when \",\" \").replace(\" at \",\" \").replace(\" any \",\" \").replace(\" before \",\" \").replace(\" them \",\" \").replace(\" same \",\" \").replace(\" and \",\" \").replace(\" been \",\" \").replace(\" have \",\" \").replace(\" in \",\" \").replace(\" will \",\" \").replace(\" on \",\" \").replace(\" does \",\" \").replace(\" yourselves \",\" \").replace(\" then \",\" \").replace(\" that \",\" \").replace(\" because \",\" \").replace(\" what \",\" \").replace(\" over \",\" \").replace(\" why \",\" \").replace(\" so \",\" \").replace(\" can \",\" \").replace(\" did \",\" \").replace(\" not \",\" \").replace(\" now \",\" \").replace(\" under \",\" \").replace(\" he \",\" \").replace(\" you \",\" \").replace(\" herself \",\" \").replace(\" has \",\" \").replace(\" just \",\" \").replace(\" where \",\" \").replace(\" too \",\" \").replace(\" only \",\" \").replace(\" myself \",\" \").replace(\" which \",\" \").replace(\" those \",\" \").replace(\" i \",\" \").replace(\" after \",\" \").replace(\" few \",\" \").replace(\" whom \",\" \").replace(\" t \",\" \").replace(\" being \",\" \").replace(\" if \",\" \").replace(\" theirs \",\" \").replace(\" my \",\" \").replace(\" against \",\" \").replace(\" a \",\" \").replace(\" by \",\" \").replace(\" doing \",\" \").replace(\" it \",\" \").replace(\" how \",\" \").replace(\" further \",\" \").replace(\" was \",\" \").replace(\" here \",\" \")\\\n",
    ".replace(\" than \",\"\").replace(\"\\r\",\" \").replace(\"\\n\",\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Indexer=SecoundJob.zipWithIndex().map(lambda ((file,contents),i):(i,file,contents))\n",
    "BookAndIndex=Indexer.map(lambda (i,file,contents):(i,str(file))).distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Done=Indexer.flatMap(lambda (i,file,contents):[(i,file, word) for word in contents.split() ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InvertedIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "outputTF = Done.map(lambda (i,file, word): (word,[int(i)]))\\\n",
    "      .reduceByKey(lambda a,b: a+b).filter(lambda x: len(list(set(x[1])))>1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputInvertedIndex=outputTF.map(lambda (x,y): (x,list(set(y))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sevens', 3, [0, 6, 15]),\n",
       " ('chatter', 2, [8, 15]),\n",
       " ('originality', 5, [14, 2, 3, 10, 6]),\n",
       " ('unnecessarily', 3, [16, 13, 14]),\n",
       " ('politician', 3, [16, 5, 14])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "InvertedIndex=outputInvertedIndex.map(lambda (word,postingList):(word,len(postingList),postingList))\n",
    "InvertedIndex.take(5)\n",
    "\n",
    "#(word,df,number of documents the word appears in, the documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF \"word\",20,0,0,15,10,0,(sum)\n",
    "## DF \"word\",numberOfDocs <- inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "InvertedIndexTable = spark.createDataFrame(InvertedIndex,[\"word\",\"df\",\"postingList\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Inverted Index Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---+--------------------+\n",
      "|         word| df|         postingList|\n",
      "+-------------+---+--------------------+\n",
      "|       sevens|  3|          [0, 6, 15]|\n",
      "|      chatter|  2|             [8, 15]|\n",
      "|  originality|  5|   [14, 2, 3, 10, 6]|\n",
      "|unnecessarily|  3|        [16, 13, 14]|\n",
      "|   politician|  3|         [16, 5, 14]|\n",
      "|     bringing| 13|[0, 2, 3, 4, 5, 6...|\n",
      "|         four| 17|[0, 1, 2, 3, 4, 5...|\n",
      "|       wooded|  2|             [16, 2]|\n",
      "|       wooden| 10|[0, 2, 3, 4, 6, 7...|\n",
      "|      broiled|  2|             [6, 15]|\n",
      "|   immunities|  2|             [2, 14]|\n",
      "|          270|  5|     [0, 8, 2, 3, 6]|\n",
      "|          272|  5|    [0, 8, 2, 10, 6]|\n",
      "|          274|  6| [0, 2, 3, 6, 8, 14]|\n",
      "|          276|  6| [0, 2, 3, 6, 8, 16]|\n",
      "|          278|  4|        [0, 8, 2, 6]|\n",
      "|      vassals|  3|          [8, 2, 10]|\n",
      "|       widger|  2|             [16, 4]|\n",
      "|        chins|  2|              [3, 6]|\n",
      "|        china|  9|[2, 3, 5, 6, 8, 1...|\n",
      "+-------------+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "InvertedIndexTable.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFData=[]\n",
    "BooksIds=[\"word\"]\n",
    "Ids=[]\n",
    "TFWordRow=[]\n",
    "for WordInput in outputTF.collect():\n",
    "    TFWordRow=[WordInput[0]]\n",
    "    for i in range(NumberOfFiles):\n",
    "        count=0\n",
    "        for docId in WordInput[1]:\n",
    "            if docId==i:\n",
    "                count=count+1\n",
    "        TFWordRow.append(float(count))\n",
    "    TFData.append(TFWordRow)\n",
    "\n",
    "for i in range(NumberOfFiles):\n",
    "    BooksIds.append(str(i))\n",
    "    Ids.append(str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "TfTable=spark.createDataFrame(TFData,BooksIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----+---+----+----+----+---+----+---+----+---+----+----+---+----+----+-----+----+\n",
      "|         word|   0|  1|   2|   3|   4|  5|   6|  7|   8|  9|  10|  11| 12|  13|  14|   15|  16|\n",
      "+-------------+----+---+----+----+----+---+----+---+----+---+----+----+---+----+----+-----+----+\n",
      "|       sevens| 1.0|0.0| 0.0| 0.0| 0.0|0.0| 7.0|0.0| 0.0|0.0| 0.0| 0.0|0.0| 0.0| 0.0|  2.0| 0.0|\n",
      "|      chatter| 0.0|0.0| 0.0| 0.0| 0.0|0.0| 0.0|0.0| 2.0|0.0| 0.0| 0.0|0.0| 0.0| 0.0|  1.0| 0.0|\n",
      "|  originality| 0.0|0.0| 1.0| 2.0| 0.0|0.0| 5.0|0.0| 0.0|0.0| 1.0| 0.0|0.0| 0.0| 1.0|  0.0| 0.0|\n",
      "|unnecessarily| 0.0|0.0| 0.0| 0.0| 0.0|0.0| 0.0|0.0| 0.0|0.0| 0.0| 0.0|0.0| 1.0| 1.0|  0.0| 3.0|\n",
      "|   politician| 0.0|0.0| 0.0| 0.0| 0.0|1.0| 0.0|0.0| 0.0|0.0| 0.0| 0.0|0.0| 0.0| 1.0|  0.0| 2.0|\n",
      "|     bringing| 3.0|0.0|22.0| 2.0|20.0|1.0|12.0|9.0| 3.0|0.0| 0.0| 0.0|4.0| 3.0| 2.0| 24.0|19.0|\n",
      "|         four|97.0|5.0|78.0|40.0|80.0|7.0|99.0|7.0|10.0|2.0|37.0|42.0|4.0|71.0|28.0|328.0|82.0|\n",
      "|       wooded| 0.0|0.0| 1.0| 0.0| 0.0|0.0| 0.0|0.0| 0.0|0.0| 0.0| 0.0|0.0| 0.0| 0.0|  0.0|12.0|\n",
      "|       wooden| 2.0|0.0| 2.0| 4.0| 3.0|0.0| 6.0|1.0| 0.0|0.0| 4.0| 3.0|0.0|17.0| 0.0|  0.0| 2.0|\n",
      "|      broiled| 0.0|0.0| 0.0| 0.0| 0.0|0.0| 1.0|0.0| 0.0|0.0| 0.0| 0.0|0.0| 0.0| 0.0|  1.0| 0.0|\n",
      "|   immunities| 0.0|0.0| 4.0| 0.0| 0.0|0.0| 0.0|0.0| 0.0|0.0| 0.0| 0.0|0.0| 0.0| 5.0|  0.0| 0.0|\n",
      "|          270| 2.0|0.0| 8.0| 3.0| 0.0|0.0| 8.0|0.0| 6.0|0.0| 0.0| 0.0|0.0| 0.0| 0.0|  0.0| 0.0|\n",
      "|          272| 1.0|0.0| 6.0| 0.0| 0.0|0.0|27.0|0.0| 3.0|0.0| 1.0| 0.0|0.0| 0.0| 0.0|  0.0| 0.0|\n",
      "|          274| 3.0|0.0| 4.0| 1.0| 0.0|0.0|12.0|0.0| 5.0|0.0| 0.0| 0.0|0.0| 0.0| 1.0|  0.0| 0.0|\n",
      "|          276| 2.0|0.0| 5.0| 1.0| 0.0|0.0| 8.0|0.0| 4.0|0.0| 0.0| 0.0|0.0| 0.0| 0.0|  0.0| 1.0|\n",
      "|          278| 8.0|0.0|11.0| 0.0| 0.0|0.0|20.0|0.0| 3.0|0.0| 0.0| 0.0|0.0| 0.0| 0.0|  0.0| 0.0|\n",
      "|      vassals| 0.0|0.0| 3.0| 0.0| 0.0|0.0| 0.0|0.0| 2.0|0.0| 1.0| 0.0|0.0| 0.0| 0.0|  0.0| 0.0|\n",
      "|       widger| 0.0|0.0| 0.0| 0.0| 2.0|0.0| 0.0|0.0| 0.0|0.0| 0.0| 0.0|0.0| 0.0| 0.0|  0.0| 2.0|\n",
      "|        chins| 0.0|0.0| 0.0| 1.0| 0.0|0.0| 1.0|0.0| 0.0|0.0| 0.0| 0.0|0.0| 0.0| 0.0|  0.0| 0.0|\n",
      "|        china| 0.0|0.0| 2.0| 5.0| 0.0|1.0|83.0|0.0| 2.0|0.0| 4.0| 0.0|3.0| 2.0| 0.0|  0.0| 1.0|\n",
      "+-------------+----+---+----+----+----+---+----+---+----+---+----+----+---+----+----+-----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TfTable.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "IDFTableData=InvertedIndex.map(lambda (x,y,z): (x,y,z,math.log10(float(NumberOfFiles)/float(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDFTable=spark.createDataFrame(IDFTableData,[\"word\",\"df\",\"postingList\",\"IDF\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+\n",
      "|         word|                IDF|\n",
      "+-------------+-------------------+\n",
      "|       sevens| 0.7533276666586115|\n",
      "|      chatter| 0.9294189257142927|\n",
      "|  originality| 0.5314789170422551|\n",
      "|unnecessarily| 0.7533276666586115|\n",
      "|   politician| 0.7533276666586115|\n",
      "|     bringing|0.11650556907143717|\n",
      "|         four|                0.0|\n",
      "|       wooded| 0.9294189257142927|\n",
      "|       wooden| 0.2304489213782739|\n",
      "|      broiled| 0.9294189257142927|\n",
      "|   immunities| 0.9294189257142927|\n",
      "|          270| 0.5314789170422551|\n",
      "|          272| 0.5314789170422551|\n",
      "|          274| 0.4522976709946303|\n",
      "|          276| 0.4522976709946303|\n",
      "|          278| 0.6283889300503115|\n",
      "|      vassals| 0.7533276666586115|\n",
      "|       widger| 0.9294189257142927|\n",
      "|        chins| 0.9294189257142927|\n",
      "|        china|0.27620641193894907|\n",
      "+-------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "IDFTable[[\"word\",\"IDF\"]].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "TfIDFInProgress=IDFTable.join(TfTable,\"word\").drop('df').drop('postingList')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Tester1=TfIDFInProgress.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RowMapForTfIdf(tup):\n",
    "    RowData=[tup[0]]\n",
    "    index=0\n",
    "    for i in tup:\n",
    "        if index>1:\n",
    "            if float(tup[index])!=0:\n",
    "                temp=float(float(1.0+math.log10(float(tup[index])))*float(tup.IDF))\n",
    "                if temp>0:\n",
    "                    RowData.append(float(float(int(temp*100))/100))\n",
    "            else:\n",
    "                RowData.append(float(0))\n",
    "        index=index+1\n",
    "    return RowData\n",
    "TFIDFRDD=Tester1.map(RowMapForTfIdf)#.filter(lambda x: x[0]!=\"shouldBeRemovedCode1\") [term]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_IDF_RDD=TFIDFRDD.filter(lambda x: len(x)>1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_IDF=spark.createDataFrame(TF_IDF_RDD,BooksIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----+---+----+----+----+----+----+----+----+---+----+----+----+----+----+----+----+\n",
      "|         word|   0|  1|   2|   3|   4|   5|   6|   7|   8|  9|  10|  11|  12|  13|  14|  15|  16|\n",
      "+-------------+----+---+----+----+----+----+----+----+----+---+----+----+----+----+----+----+----+\n",
      "|          296|0.45|0.0|0.76|0.76|0.45| 0.0|1.12| 0.0| 0.8|0.0| 0.0| 0.0| 0.0| 0.0| 0.0| 0.0| 0.0|\n",
      "|          467| 0.0|0.0| 1.2| 0.0| 0.0| 0.0|1.81| 0.0| 0.0|0.0| 0.0| 0.0| 0.0| 0.0| 0.0| 0.0| 0.0|\n",
      "|          675| 0.0|0.0|0.92| 0.0| 0.0| 0.0| 0.0| 0.0| 0.0|0.0| 0.0| 0.0| 0.0| 0.0|0.92| 0.0| 0.0|\n",
      "| accumulation|0.62|0.0| 0.0| 0.0| 0.0| 0.0|0.62| 0.0|0.62|0.0| 0.0| 0.0| 0.0| 0.0|0.81| 0.0| 0.0|\n",
      "|    ammonites|0.62|0.0| 0.0| 0.0| 0.0| 0.0|0.92| 0.0| 0.0|0.0| 0.0| 0.0|0.62| 0.0| 0.0|1.48| 0.0|\n",
      "|apprehensions| 0.0|0.0|1.11| 0.0| 0.0| 0.0|0.81| 0.0| 0.0|0.0| 0.0| 0.0| 0.0| 0.0|0.62| 0.0|1.06|\n",
      "|    arguments| 0.0|0.0|0.47|0.29| 0.4| 0.0|0.39| 0.0|0.34|0.0|0.39| 0.0|0.34| 0.0|0.36|0.23| 0.4|\n",
      "|     ashkenaz| 0.0|0.0| 0.0|0.92| 0.0| 0.0| 0.0| 0.0| 0.0|0.0| 0.0| 0.0| 0.0| 0.0| 0.0|0.92| 0.0|\n",
      "|      barrier| 0.0|0.0|0.38|0.38| 0.0| 0.0|0.38| 0.0| 0.0|0.0| 0.5| 0.0| 0.0|0.38|0.38| 0.0| 0.8|\n",
      "|       biting| 0.0|0.0| 0.0| 0.0| 0.0|0.92| 1.2| 0.0| 0.0|0.0| 0.0| 0.0| 0.0| 0.0| 0.0| 0.0| 0.0|\n",
      "|     blackish| 0.0|0.0| 0.0|0.92| 0.0| 0.0| 0.0| 0.0| 0.0|0.0| 0.0| 0.0| 0.0| 0.0| 0.0|0.92| 0.0|\n",
      "|      blossom|0.58|0.0|0.58| 0.0| 0.0|0.45|0.58| 0.0| 0.0|0.0| 0.0| 0.0| 0.0|0.58| 0.0| 0.8| 0.0|\n",
      "|    bookshelf| 0.0|0.0| 0.0| 0.0| 0.0|0.92| 0.0| 0.0| 0.0|0.0| 0.0| 0.0| 0.0|0.92| 0.0| 0.0| 0.0|\n",
      "|     brackets| 0.0|0.0| 0.0|0.62| 0.0|0.81|0.62| 0.0| 0.0|0.0| 0.0|0.62| 0.0| 0.0| 0.0| 0.0| 0.0|\n",
      "|       brands| 0.0|0.0| 0.0| 0.0| 0.0| 0.0|1.57| 0.0| 0.0|0.0| 0.0| 0.0| 0.0| 0.0| 0.0|0.92| 0.0|\n",
      "|        brant| 0.0|0.0| 0.0|0.92| 0.0| 0.0| 0.0| 0.0| 0.0|0.0| 0.0| 0.0| 0.0|0.92| 0.0| 0.0| 0.0|\n",
      "|     briefest| 0.0|0.0| 0.0| 0.0| 0.0| 0.0| 0.0| 0.0|0.75|0.0| 0.0| 0.0|0.75| 0.0| 0.0| 0.0|0.75|\n",
      "|     cautious| 0.0|0.0|0.69| 0.0|0.69|0.53| 0.0| 0.0|0.53|0.0| 0.0| 0.0| 0.0| 0.0| 0.0| 0.0| 1.1|\n",
      "|       ceylon| 0.0|0.0|1.11|0.75| 0.0| 0.0|1.71| 0.0| 0.0|0.0| 0.0| 0.0| 0.0| 0.0| 0.0| 0.0| 0.0|\n",
      "|       coaxed| 0.0|0.0| 0.0| 0.0| 0.0| 0.0| 0.0|0.92| 0.0|0.0| 0.0| 0.0| 0.0|0.92| 0.0| 0.0| 0.0|\n",
      "+-------------+----+---+----+----+----+----+----+----+----+---+----+----+----+----+----+----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TF_IDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogTFTable(tup):\n",
    "    RowData=[str(tup[0])]\n",
    "    index=0\n",
    "    for i in tup:\n",
    "        if index>0:\n",
    "            if tup[index]!=0:\n",
    "                RowData.append(1.0+math.log10(tup[index]))\n",
    "            else:\n",
    "                RowData.append(float(0))\n",
    "        index=index+1\n",
    "    return RowData\n",
    "LogTFRDD=TfTable.rdd.map(LogTFTable)\n",
    "LogTFRDD\n",
    "TF_DataFrame=spark.createDataFrame(LogTFRDD,BooksIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=0\n",
    "docsVec=[]\n",
    "for i in BooksIds:\n",
    "    if i!=\"word\":\n",
    "        vals=TF_DataFrame[[str(i)]].rdd.filter(lambda z: z[0]!=0.0).map(tuple).map(lambda t: t[0])\n",
    "        for tup in vals.collect():\n",
    "            temp=temp+math.pow(tup,2)\n",
    "        docsVec.append(1/math.pow(temp,0.5))\n",
    "        temp=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CosTable=[]\n",
    "for i in LogTFRDD.collect():\n",
    "    row=[i[0]]\n",
    "    index=1\n",
    "    while index<NumberOfFiles+1:\n",
    "        row.append(i[index]*docsVec[index-1])\n",
    "        index=index+1\n",
    "    CosTable.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cos_DataFrame=spark.createDataFrame(CosTable,BooksIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=0\n",
    "CosSimilartyWithDoc1=[]\n",
    "for CheckSimilartyForBookNumber in BooksIds:\n",
    "    if CheckSimilartyForBookNumber!=\"word\":\n",
    "        for i in BooksIds:\n",
    "            if i!=\"word\":\n",
    "                if int(i)>int(CheckSimilartyForBookNumber):\n",
    "                    if i!=str(CheckSimilartyForBookNumber):\n",
    "                        vals=Cos_DataFrame[[str(CheckSimilartyForBookNumber),i]].rdd.map(tuple)\n",
    "                        for tup in vals.collect():\n",
    "                            temp=float(tup[0])*float(tup[1])+float(temp)\n",
    "                        CosSimilartyWithDoc1.append((CheckSimilartyForBookNumber,str(i),temp))\n",
    "                        temp=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "CosSimilartyWithDocTable=spark.createDataFrame(CosSimilartyWithDoc1,[\"book1\",\"book2\",\"rank\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+------------------+\n",
      "|book1|book2|              rank|\n",
      "+-----+-----+------------------+\n",
      "|    2|    6|0.7458061960541694|\n",
      "|    3|    6|0.7260409436314755|\n",
      "|    0|    6|0.7122226075611113|\n",
      "|    6|    8|0.7062522479188156|\n",
      "|    2|    3|0.7019142121709496|\n",
      "|    2|   14|0.6977176570070522|\n",
      "|   11|   13|0.6880136221856791|\n",
      "|    2|   10|0.6842634185925098|\n",
      "|    4|   15|0.6773668084773767|\n",
      "|    2|    8|0.6770798144221256|\n",
      "|    3|    8|0.6736129823298831|\n",
      "|    2|   16| 0.668850521749075|\n",
      "|    7|   15| 0.660373639437973|\n",
      "|    0|    3|0.6587386267026158|\n",
      "|   10|   14|0.6553075101443503|\n",
      "|    4|    6| 0.654443062428649|\n",
      "|   14|   16|0.6533373040313876|\n",
      "|    1|   11|0.6526886881132524|\n",
      "|    0|    2|0.6521038396318022|\n",
      "|    2|    4|0.6516589539999386|\n",
      "+-----+-----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CosSimilartyWithDocTable.orderBy('rank', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7, 'The Wonder Book of Bible Stories'),\n",
       " (11, 'Girls and Athletics by Mary C. Morgan'),\n",
       " (4,\n",
       "  'The Wars of the Jews; Or, The History of the Destruction of Jerusalem by Josephus'),\n",
       " (0, 'The Astronomy of the Bible by E Walter Maunder'),\n",
       " (15, 'The King James Version of the Bible'),\n",
       " (3, 'The Jew, The Gypsy and El Islam by Sir Richard Francis Burton'),\n",
       " (14,\n",
       "  'Black and White Land Labor and Politics in the South by Timothy Thomas Fortune'),\n",
       " (12,\n",
       "  'The History of the Ten Lost Tribes Anglo Israelism Examined by David Baron'),\n",
       " (8, 'The Jews among the Greeks and Romans by Max Radin'),\n",
       " (2,\n",
       "  'History of the Negro Race in America From 1619 to 1880 Vol 1 by Williams'),\n",
       " (16, 'On War by Carl von Clausewitz'),\n",
       " (9,\n",
       "  'The Black Man the Father of Civilization Proven by Biblical History by Webb'),\n",
       " (6, 'Bible Myths and their Parallels'),\n",
       " (1, 'Association Football and How To Play It'),\n",
       " (5, 'Sport The Gold Bat'),\n",
       " (10, 'The Negro by W E B Du Bois'),\n",
       " (13, 'Outdoor Sports and Games by Claude Harris Miller')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BookAndIndex.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Similarty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the black community suffered from racism\n",
      "+---+--------------------+\n",
      "| id|              Vector|\n",
      "+---+--------------------+\n",
      "|  8| 0.00607094571234321|\n",
      "| 10|0.006030110099554556|\n",
      "|  3|0.005581351642529...|\n",
      "| 14|0.005342092092682165|\n",
      "|  5|0.004936375099129895|\n",
      "| 16|0.004758775465715...|\n",
      "|  2| 0.00473344003184238|\n",
      "|  6|0.004307981684093991|\n",
      "|  0|0.003829271241210...|\n",
      "| 12|0.003549828926600898|\n",
      "+---+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "devine punishment\n",
      "+---+--------------------+\n",
      "| id|              Vector|\n",
      "+---+--------------------+\n",
      "| 12|0.002319904132610091|\n",
      "|  4|0.002162164197196683|\n",
      "|  7|0.001877536080726...|\n",
      "|  8|0.001764238011328...|\n",
      "|  2|0.001649728756195...|\n",
      "| 14|0.001624166864780...|\n",
      "| 10|0.001554216375240...|\n",
      "|  3|0.001523182725923...|\n",
      "| 15|0.001516102686988...|\n",
      "|  1|0.001451885138153...|\n",
      "+---+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "israel\n",
      "+---+--------------------+\n",
      "| id|              Vector|\n",
      "+---+--------------------+\n",
      "| 12|0.009254745594635657|\n",
      "|  7| 0.00694781572325833|\n",
      "| 15|0.005477210016998302|\n",
      "|  0|0.004876681903729209|\n",
      "|  3|0.003970182698406301|\n",
      "|  6|0.003776790742224891|\n",
      "|  8|0.003051879548507367|\n",
      "|  4|0.002703516410817...|\n",
      "|  2|0.002593808803117...|\n",
      "| 14|0.001806716208580...|\n",
      "+---+--------------------+\n",
      "\n",
      "training camp\n",
      "+---+--------------------+\n",
      "| id|              Vector|\n",
      "+---+--------------------+\n",
      "| 13|0.004226706853796114|\n",
      "| 11|0.003586798310909...|\n",
      "|  1|0.003400928677559...|\n",
      "|  7|0.003245391927511...|\n",
      "|  9|0.003088749142661185|\n",
      "| 16|0.002628762445044606|\n",
      "|  3|0.002414360623503...|\n",
      "|  5| 0.00236107168929152|\n",
      "|  8|0.002171147858788986|\n",
      "|  2|0.002116087235128...|\n",
      "+---+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "competition\n",
      "+---+--------------------+\n",
      "| id|              Vector|\n",
      "+---+--------------------+\n",
      "|  1|0.006120515891660301|\n",
      "| 11|0.005432248045003297|\n",
      "|  5|0.005319262246060318|\n",
      "| 14|0.004712226114011766|\n",
      "| 10|0.004089671977833558|\n",
      "| 13|0.002953755903941846|\n",
      "| 16|0.002930803063021263|\n",
      "|  0|0.002049967306618...|\n",
      "|  6|0.001464997408831...|\n",
      "+---+--------------------+\n",
      "\n",
      "war\n",
      "+---+--------------------+\n",
      "| id|              Vector|\n",
      "+---+--------------------+\n",
      "|  9|0.002306033305446...|\n",
      "| 16|0.002203168752419181|\n",
      "| 10|0.001997645476533...|\n",
      "|  4|0.001992755674126301|\n",
      "|  7|0.001912726908560...|\n",
      "| 14|0.001868246053876...|\n",
      "|  2|0.001563787639922...|\n",
      "| 15|0.001523113986886...|\n",
      "|  8|0.001453502591274...|\n",
      "|  3|0.001167614523767...|\n",
      "+---+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "you play until the last minute\n",
      "+---+--------------------+\n",
      "| id|              Vector|\n",
      "+---+--------------------+\n",
      "| 11|0.006733315995931454|\n",
      "|  5|0.006279719761296886|\n",
      "| 13|0.005603689410927797|\n",
      "|  1|0.005330434369349...|\n",
      "|  0|0.003885718827935779|\n",
      "| 16|0.003830860606963084|\n",
      "|  2|0.003258542780449...|\n",
      "|  3|0.002966185477389...|\n",
      "| 14|0.002760688013827...|\n",
      "|  6|0.002393901380900074|\n",
      "+---+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "you win some you lose some\n",
      "+---+--------------------+\n",
      "| id|              Vector|\n",
      "+---+--------------------+\n",
      "| 13|0.004038812209470027|\n",
      "|  1| 0.00403355651197481|\n",
      "|  5| 0.00395851444397056|\n",
      "|  7|0.003813233493310869|\n",
      "| 11|0.003556962940946...|\n",
      "| 16|0.002738403654450...|\n",
      "|  3|0.002396586210646...|\n",
      "| 14|0.002376726736364...|\n",
      "| 15|0.002311056449599...|\n",
      "| 12|0.002187575757715355|\n",
      "+---+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "he war lingered for days on end\n",
      "+---+--------------------+\n",
      "| id|              Vector|\n",
      "+---+--------------------+\n",
      "|  9|0.002306033305446...|\n",
      "| 16|0.002203168752419181|\n",
      "| 10|0.001997645476533...|\n",
      "|  4|0.001992755674126301|\n",
      "|  7|0.001912726908560...|\n",
      "| 14|0.001868246053876...|\n",
      "|  2|0.001563787639922...|\n",
      "| 15|0.001523113986886...|\n",
      "|  8|0.001453502591274...|\n",
      "|  3|0.001167614523767...|\n",
      "+---+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "brilliant strategy\n",
      "+---+--------------------+\n",
      "| id|              Vector|\n",
      "+---+--------------------+\n",
      "| 16|0.010783615224572702|\n",
      "|  0|0.007601189314265919|\n",
      "|  5|0.007374662986574144|\n",
      "|  1|0.007158225687551301|\n",
      "| 10|0.005534173930219322|\n",
      "|  2|0.003978194211391439|\n",
      "| 13|0.003167450916278...|\n",
      "|  9|0.002907720938478544|\n",
      "| 14|0.002374570364898821|\n",
      "|  6|0.002236590057842...|\n",
      "+---+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#NumberOfApp*IDF*vector\n",
    "\n",
    "\n",
    "def QuerySimilarty(Query):\n",
    "    WordXIDFxW=[]\n",
    "    WordXIDFxWxCW=[]\n",
    "    DocIndex=0\n",
    "    QueryRdd = sc.parallelize([(\"Query\",Query.lower())])\n",
    "    QueryWordsSplited=QueryRdd.flatMap(lambda (file,contents):[(word,1) for word in contents.split()]).reduceByKey(lambda a,b: a+b)\n",
    "    #[(term1,tf),(term2,tf)]\n",
    "    for tup in QueryWordsSplited.collect():\n",
    "        CheckNotEmpty=GetIDF(tup[0])\n",
    "        if CheckNotEmpty>0:\n",
    "            if CheckNotEmpty!=0:\n",
    "                WordXIDFxW.append([tup[0], float(tup[1]) *GetIDF(tup[0])])                \n",
    "    #[(term1,tf*IDF),(term2,tf*IDF),(term3,tf*IDF)]\n",
    "    for tup in WordXIDFxW:\n",
    "        DocIndex=0\n",
    "        while DocIndex<NumberOfFiles:\n",
    "            WordXIDFxWxCW.append([str(DocIndex),tup[0],float(tup[1])*float(GetCosValOfWordInDoc([tup[0],DocIndex]))]) \n",
    "            DocIndex=DocIndex+1\n",
    "    #[(docId1,term1,tf*IDF*Vec),(docId1,term2,tf*IDF*Vec)]\n",
    "    return GetBest10(WordXIDFxWxCW)\n",
    "\n",
    "def GetIDF(Term):\n",
    "    temp=IDFTableData.filter(lambda x: x[0]==Term).collect()\n",
    "    if temp!=[]:\n",
    "        return IDFTableData.filter(lambda x: x[0]==Term).collect()[0][3]\n",
    "    else: 0\n",
    "\n",
    "def GetCosValOfWordInDoc(DocXTerm):\n",
    "    return Cos_DataFrame.rdd.filter(lambda x: x[0]==DocXTerm[0]).collect()[0][str(DocXTerm[1])]\n",
    "\n",
    "def GetBest10(DocXtermXscore):\n",
    "    ScoreDataFrame=spark.createDataFrame(DocXtermXscore,[\"id\",\"term\",\"vector\"])\n",
    "    ScoreDataFrame=ScoreDataFrame.drop(\"term\")\n",
    "    RDDScoreDataFrame=ScoreDataFrame.rdd.map(tuple).reduceByKey(lambda a,b: a+b).filter(lambda x: x[1]>0)\n",
    "    ScoreDataFrame=spark.createDataFrame(RDDScoreDataFrame,[\"id\",\"Vector\"]).orderBy('vector', ascending=False)\n",
    "    \n",
    "    return ScoreDataFrame.show(10)\n",
    "    \n",
    "print(\"the black community suffered from racism\")\n",
    "QuerySimilarty(\"the black community suffered from racism\")\n",
    "print(\"devine punishment\")\n",
    "QuerySimilarty(\"devine punishment\")\n",
    "print(\"israel\")\n",
    "QuerySimilarty(\"israel\")\n",
    "print(\"training camp\")\n",
    "QuerySimilarty(\"training camp\")\n",
    "print(\"competition\")\n",
    "QuerySimilarty(\"competition\")\n",
    "print(\"war\")\n",
    "QuerySimilarty(\"war\")\n",
    "print(\"you play until the last minute\")\n",
    "QuerySimilarty(\"you play until the last minute\")\n",
    "print(\"you win some you lose some\")\n",
    "QuerySimilarty(\"you win some you lose some\")\n",
    "print(\"he war lingered for days on end\")\n",
    "QuerySimilarty(\"he war lingered for days on end\")\n",
    "print(\"brilliant strategy\")\n",
    "QuerySimilarty(\"brilliant strategy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Subjects : Sport, History, Sience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ultimate form\n",
    "Tempo=Cos_DataFrame.drop(\"word\")\n",
    "SizeOfVector=Tempo[[\"1\"]].rdd.map(tuple).count()\n",
    "Doc=[]\n",
    "for i in Ids:\n",
    "    Docs=[i]\n",
    "    DocsIds=[]\n",
    "    col=Tempo[[i]].rdd.map(tuple)\n",
    "    for row in col.collect():\n",
    "        DocsIds.append(row[0])\n",
    "    Docs.append(DocsIds)\n",
    "    Doc.append(Docs)\n",
    "DocsVectorsTable=spark.createDataFrame(Doc)\n",
    "DocsVectors=DocsVectorsTable.rdd.map(tuple).map(lambda x: (x[0],np.array(x[1])))\n",
    "\n",
    "\n",
    "#(DOCID,[vec])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# we could do this algoritem without np But It took more then 30 min to run \n",
    "we can replace every small calc on the vector with function, but np works much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVector (input):\n",
    "    return DocsVectors.filter(lambda x: x[0]==str(input)).collect()[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "VectorsList=[]\n",
    "for Id in Ids:\n",
    "    VectorsList.append(getVector(Id))\n",
    "EmptyVec=[]\n",
    "i=0\n",
    "while i<SizeOfVector:\n",
    "    EmptyVec.append(0)\n",
    "    i=i+1\n",
    "EmptyVec=np.array(EmptyVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CheckSimilarty (v1,v2):\n",
    "    v=v1*v2\n",
    "    sumV=0\n",
    "    for i in v:\n",
    "        sumV=sumV+i\n",
    "    return sumV\n",
    "\n",
    "def avgVec (v):\n",
    "    tv=EmptyVec\n",
    "    bol=0\n",
    "    for i in v:\n",
    "        tv=tv+getVector(i)\n",
    "    return tv/len(v)\n",
    "\n",
    "\n",
    "def getEmptyCluster(inK):\n",
    "    counterForEmpty=0\n",
    "    Temp=[]\n",
    "    while counterForEmpty<inK:\n",
    "        Temp.append([])\n",
    "        counterForEmpty=counterForEmpty+1\n",
    "    return NewCluster\n",
    "\n",
    "def getRandomKnumbers(input,limit):\n",
    "    return random.sample(range(0, limit+1), input)\n",
    "\n",
    "def getEmptyList ():\n",
    "    return []\n",
    "\n",
    "def calcCentroide(ListOfVectorIndexes):\n",
    "    tv=EmptyVec\n",
    "    bol=0\n",
    "    for i in ListOfVectorIndexes:\n",
    "        tv=tv+getVector(i)\n",
    "    return tv/len(ListOfVectorIndexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run1KmeanClustering(k, numOfIterations):\n",
    "    arr=[]\n",
    "    innerArr=[]\n",
    "    Cluster=[]\n",
    "    NewCluster=[]\n",
    "    TempCluster=[]\n",
    "    i=0\n",
    "    \n",
    "    RandomArr=getRandomKnumbers(k, NumberOfFiles-1)\n",
    "    while i<k:\n",
    "        arr.append([VectorsList[RandomArr[i]]])\n",
    "        Cluster.append([str(RandomArr[i])])\n",
    "        NewCluster.append([])\n",
    "        TempCluster.append([])\n",
    "        i=i+1\n",
    "    i=0\n",
    "\n",
    "#  I choose random files they already not in order\n",
    "#Now lets beggin\n",
    "    VectorId=-1\n",
    "    ClusterId=-1\n",
    "    while i<numOfIterations:                                    #4\n",
    "        Centroids=[]\n",
    "        for c in Cluster:\n",
    "            Centroids.append(calcCentroide(c))\n",
    "                \n",
    "        for vec in VectorsList:\n",
    "            VectorId=VectorId+1\n",
    "            bestCluster=[0,0]\n",
    "        ####################################################\n",
    "            for cluster in Cluster:                             #3\n",
    "                ClusterId=ClusterId+1\n",
    "                for Checker in cluster:\n",
    "                    Rank=CheckSimilarty(vec,Centroids[ClusterId])\n",
    "                    \n",
    "                if Rank>bestCluster[1]:\n",
    "                    bestCluster=[]\n",
    "                    bestCluster.append(ClusterId)\n",
    "                    bestCluster.append(Rank)\n",
    "        ####################################################\n",
    "            TempCluster[bestCluster[0]].append(str(VectorId))\n",
    "            ClusterId=-1\n",
    "    ########################################################\n",
    "        j=0\n",
    "        VectorId=-1\n",
    "        for x in TempCluster:\n",
    "            arr[j]=[]\n",
    "            for n in x:\n",
    "                arr[j].append(VectorsList[int(n)-1])\n",
    "            j=j+1\n",
    "        i=i+1\n",
    "        Cluster=TempCluster\n",
    "        counterForEmpty=0\n",
    "        TempCluster=[]\n",
    "        while counterForEmpty<k:\n",
    "            TempCluster.append([])\n",
    "            counterForEmpty=counterForEmpty+1\n",
    "    return Cluster\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RankCluster (ArrOfIndexes):\n",
    "    rank=0\n",
    "    avg=avgVec(ArrOfIndexes)\n",
    "    for index in ArrOfIndexes:\n",
    "        rank=rank+CheckSimilarty(getVector(index),avg)\n",
    "    return rank\n",
    "\n",
    "def RankClustering (ArrOfClusters):#k clusters\n",
    "    Rank=0\n",
    "    for cluster in ArrOfClusters:\n",
    "        Rank=RankCluster(cluster)+Rank \n",
    "    return Rank\n",
    "\n",
    "def KMeanAlgoritem(K_Clusters,NumOfTests):\n",
    "    TestsResults=[]\n",
    "    ClusteringRank=[]\n",
    "    counterKMeanTests=0\n",
    "    RankMax=0\n",
    "    while counterKMeanTests<NumOfTests:\n",
    "        TestsResults.append(run1KmeanClustering(K_Clusters, 3))#(k,numberOfClusteringFix)\n",
    "        counterKMeanTests=counterKMeanTests+1\n",
    "    #Now we have many clustering options\n",
    "    for Test in TestsResults:\n",
    "        RankIt=RankClustering(Test)\n",
    "        if RankIt>RankMax:\n",
    "            RankMax=RankIt\n",
    "            res=Test\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resu=KMeanAlgoritem(3,10)#(k,NUMBER-OF-RUNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['0', '2', '3', '4', '6', '8', '10', '14', '15', '16'],\n",
       " ['1', '5', '11', '13'],\n",
       " ['7', '9', '12']]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Astronomy of the Bible by E Walter Maunder\n",
      "History of the Negro Race in America From 1619 to 1880 Vol 1 by Williams\n",
      "The Jew, The Gypsy and El Islam by Sir Richard Francis Burton\n",
      "The Wars of the Jews; Or, The History of the Destruction of Jerusalem by Josephus\n",
      "Bible Myths and their Parallels\n",
      "The Jews among the Greeks and Romans by Max Radin\n",
      "The Negro by W E B Du Bois\n",
      "Black and White Land Labor and Politics in the South by Timothy Thomas Fortune\n",
      "The King James Version of the Bible\n",
      "On War by Carl von Clausewitz\n",
      " \n",
      "Association Football and How To Play It\n",
      "Sport The Gold Bat\n",
      "Girls and Athletics by Mary C. Morgan\n",
      "Outdoor Sports and Games by Claude Harris Miller\n",
      " \n",
      "The Wonder Book of Bible Stories\n",
      "The Black Man the Father of Civilization Proven by Biblical History by Webb\n",
      "The History of the Ten Lost Tribes Anglo Israelism Examined by David Baron\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for r in resu:\n",
    "    for i in r:\n",
    "        print(BookAndIndex.filter(lambda (x,y): str(x)==str(i)).collect()[0][1])\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7, 'The Wonder Book of Bible Stories'),\n",
       " (11, 'Girls and Athletics by Mary C. Morgan'),\n",
       " (4,\n",
       "  'The Wars of the Jews; Or, The History of the Destruction of Jerusalem by Josephus'),\n",
       " (0, 'The Astronomy of the Bible by E Walter Maunder'),\n",
       " (15, 'The King James Version of the Bible'),\n",
       " (3, 'The Jew, The Gypsy and El Islam by Sir Richard Francis Burton'),\n",
       " (14,\n",
       "  'Black and White Land Labor and Politics in the South by Timothy Thomas Fortune'),\n",
       " (12,\n",
       "  'The History of the Ten Lost Tribes Anglo Israelism Examined by David Baron'),\n",
       " (8, 'The Jews among the Greeks and Romans by Max Radin'),\n",
       " (2,\n",
       "  'History of the Negro Race in America From 1619 to 1880 Vol 1 by Williams'),\n",
       " (16, 'On War by Carl von Clausewitz'),\n",
       " (9,\n",
       "  'The Black Man the Father of Civilization Proven by Biblical History by Webb'),\n",
       " (6, 'Bible Myths and their Parallels'),\n",
       " (1, 'Association Football and How To Play It'),\n",
       " (5, 'Sport The Gold Bat'),\n",
       " (10, 'The Negro by W E B Du Bois'),\n",
       " (13, 'Outdoor Sports and Games by Claude Harris Miller')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BookAndIndex.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
